{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua9cInUb3rMY"
      },
      "source": [
        "# Семинар 9 - Методы построения оптического потока по последовательности изображений\n",
        "\n",
        "**Этот семинар содержит оцениваемое домашнее задание**\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siHO0-PC3rMZ"
      },
      "source": [
        "Источник - https://habr.com/ru/post/201406/\n",
        "\n",
        "$\\textbf{Task statement}$: Оптический поток (ОП) – изображение видимого движения, представляющее собой сдвиг каждой точки (пикселя) между двумя изображениями.\n",
        "\n",
        "По сути, он представляет собой поле скоростей. Суть ОП в том, что для каждой точки изображения $I_{t_0} (\\vec{r})$ находится такой вектор сдвига $\\delta \\vec{r}$, чтобы было соответсвие между исходной точкой и точкой на следущем фрейме $I_{t_1} (\\vec{r} + \\delta \\vec{r})$. В качестве метрики соответвия берут близость интенсивности пикселей, беря во внимание маленькую разницу по времени между кадрами: $\\delta{t} = t_{1} - t_{0}$. В более точных методах точку можно привязывать к объекту на основе, например, выделения ключевых точек, а также считать градиенты вокруг точки, лапласианы и проч.\n",
        "\n",
        "$\\textbf{For what}$: Определение собственной скорости, Определение локализации, Улучшение методов трекинга объектов, сегментации, Детектирование событий, Сжатие видеопотока и проч.\n",
        "\n",
        "![](data/tennis.png)\n",
        "\n",
        "Разделяют 2 вида оптического потока - плотный (dense) [Farneback method, neural nets], работающий с целым изображением, и выборочный (sparse) [Lucas-Kanade method], работающий с ключевыми точками"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2c-3th-3rMa",
        "outputId": "18f4ed30-a52f-4ac4-9004-7ff08bc5bca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-18 19:19:44--  https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4\n",
            "Resolving www.bogotobogo.com (www.bogotobogo.com)... 173.254.30.214\n",
            "Connecting to www.bogotobogo.com (www.bogotobogo.com)|173.254.30.214|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2018126 (1.9M) [video/mp4]\n",
            "Saving to: ‘data/slow_traffic_small.mp4’\n",
            "\n",
            "data/slow_traffic_s 100%[===================>]   1.92M  4.95MB/s    in 0.4s    \n",
            "\n",
            "2025-05-18 19:19:45 (4.95 MB/s) - ‘data/slow_traffic_small.mp4’ saved [2018126/2018126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O data/slow_traffic_small.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kO_70sfm3rMa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xJ_tsb_3rMb"
      },
      "source": [
        "## Lucas-Kanade (sparse)\n",
        "\n",
        "Пусть $I_{1} = I(x, y, t_{1})$ интенсивность в некоторой точке (x, y) на первом изображении (т. е. в момент времени t). На втором изображении эта точка сдвинулась на (dx, dy), при этом прошло время dt, тогда $I_{2} = I(x + dx, y + dx, t_{1} + dt) \\approx I_{1} + I_{x}dx + I_{y}dy +  I_{t}dt$. Из постановки задачи следует, что интенсивность пикселя не изменилась, тогда $I_{1} = I_{2}$. Далее определяем $dx, dy$.\n",
        "\n",
        "Самое простое решение проблемы – алгоритм Лукаса-Канаде. У нас же на изображении объекты размером больше 1 пикселя, значит, скорее всего, в окрестности текущей точки у других точек будут примерно такие же сдвиги. Поэтому мы возьмем окно вокруг этой точки и минимизируем (по МНК) в нем суммарную погрешность с весовыми коэффициентами, распределенными по Гауссу, то есть так, чтобы наибольший вес имели пиксели, ближе всего находящиеся к исследуемому.\n",
        "\n",
        "**Полезные материалы:**\n",
        "- цикл видео-лекций от First Principles of Computer Vision, посвященный Optical Flow и алгоритму Lucas-Kanade: https://youtube.com/playlist?list=PL2zRqk16wsdoYzrWStffqBAoUY8XdvatV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU90xHu93rMb"
      },
      "source": [
        "### Вопрос 1\n",
        "\n",
        "Перечислите три основных предположения, на которых базируется метод Lucas-Kanade. Почему каждое из них важно для корректной работы алгоритма?\n",
        "\n",
        "**Ответ:**\n",
        "1. Постоянство интенсивности пикселя:\n",
        "\n",
        "Интенсивность (яркость) пикселя остается неизменной между двумя последовательными кадрами;\n",
        "\n",
        "2. Малость смещения:\n",
        "\n",
        "Сдвиги пикселей между кадрами малы (в пределах нескольких пикселей), т.е. можно использовать первый порядок разложения в ряд Тейлора;\n",
        "\n",
        "3. Пространственная когерентность:\n",
        "\n",
        "В маленькой окрестности предполагается, что все пиксели движутся одинаково, то есть имеют одинаковый вектор оптического потока."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVp_dgNu3rMb"
      },
      "source": [
        "### Вопрос 2\n",
        "\n",
        "Объясните, зачем нужен пирамидальный подход в алгоритме Lucas-Kanade. Какую проблему он решает и как именно?\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "Пирамидальный подход нужен для обработки больших сдвигов между кадрами, которые нарушают предположение о малости движения.\n",
        "\n",
        "Он решает проблему больших движений объектов, которые нельзя корректно аппроксимировать линейно на исходном разрешении.\n",
        "\n",
        "Принцип работы:\n",
        "1. Строятся пирамиды изображений, т.е. последовательность уменьшенных копий;\n",
        "2. Оптический поток сначала оценивается на низком разрешении, где сдвиги визуально меньше;\n",
        "3. Затем этот поток пропагируется и уточняется на более высоких уровнях до оригинального разрешения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4x2BQHm3rMb"
      },
      "source": [
        "### Вопрос 3\n",
        "\n",
        "С какими проблемами может столкнуться алгоритм Lucas-Kanade при отслеживании точек на видео? Назовите минимум три ограничения.\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "1. Быстрые и большие движения (нарушается предположение о малом смещении);\n",
        "2. Однородные или текстурно-пустые области, т.к. в них невозможно надёжно вычислить градиенты (матрица системы становится вырожденной);\n",
        "3. Изменения освещения или яркости (Нарушается предположение о постоянстве интенсивности)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwAUAKWh3rMb"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Напишите реализацию Лукаса-Канаде c помощью numpy и cv2. Сравните с реализацией `cv2.calcOpticalFlowPyrLK`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_image_pyramid(image, num_levels, scale_factor=0.5):\n",
        "    pyramid = [image.copy()]\n",
        "    current_image = image.copy()\n",
        "\n",
        "    for _ in range(1, num_levels):\n",
        "        new_size = (int(current_image.shape[1] * scale_factor), int(current_image.shape[0] * scale_factor))\n",
        "        current_image = cv2.resize(current_image, new_size, interpolation=cv2.INTER_LINEAR)\n",
        "        pyramid.append(current_image)\n",
        "\n",
        "    return pyramid\n",
        "\n",
        "def compute_image_gradients(image):\n",
        "    Ix = cv2.Sobel(image, cv2.CV_64F, dx=1, dy=0, ksize=3)\n",
        "    Iy = cv2.Sobel(image, cv2.CV_64F, dx=0, dy=1, ksize=3)\n",
        "    return Ix, Iy\n"
      ],
      "metadata": {
        "id": "YCIa07UV9SfL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_lk_optical_flow_point(Ix, Iy, It, window_size=5):\n",
        "    A = np.array([\n",
        "        [np.sum(Ix * Ix), np.sum(Ix * Iy)],\n",
        "        [np.sum(Ix * Iy), np.sum(Iy * Iy)]\n",
        "    ])\n",
        "\n",
        "    b = np.array([\n",
        "        -np.sum(Ix * It),\n",
        "        -np.sum(Iy * It)\n",
        "    ])\n",
        "\n",
        "    # Проверяем обусловленность матрицы A через собственные значения\n",
        "    try:\n",
        "        eigenvalues = np.linalg.eigvals(A)\n",
        "        if np.min(eigenvalues) < 1e-4 or np.isnan(eigenvalues).any():\n",
        "            return None, None\n",
        "\n",
        "        # Решаем систему уравнений\n",
        "        flow = np.linalg.solve(A, b)\n",
        "        return flow[0], flow[1]\n",
        "    except np.linalg.LinAlgError:\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "tzTK-2i2Qos_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_lk_optical_flow_for_patch(prev_patch, curr_patch, window_size=5):\n",
        "    # Пространственные градиенты\n",
        "    Ix, Iy = compute_image_gradients(prev_patch)\n",
        "    # 2. Временной градиент\n",
        "    It = curr_patch - prev_patch\n",
        "    # 3. ОП\n",
        "    u, v = compute_lk_optical_flow_point(Ix, Iy, It, window_size=window_size)\n",
        "    return u, v"
      ],
      "metadata": {
        "id": "A6sXpEMb9SlC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def track_point_with_pyramid_lk(prev_pyramid, curr_pyramid, point, window_size=15, max_iterations=10, epsilon=0.01):\n",
        "\n",
        "    num_levels = len(prev_pyramid)\n",
        "    point = np.array([point[0], point[1]], dtype=np.float32)\n",
        "\n",
        "    # Начальное смещение\n",
        "    flow = np.zeros(2, dtype=np.float32)\n",
        "\n",
        "    # Обрабатываем уровни пирамиды от верхнего (маленького) к нижнему (большому)\n",
        "    for level in range(num_levels - 1, -1, -1):\n",
        "        # Масштабируем точку для текущего уровня\n",
        "        scale = 1.0 / (2 ** level) if level > 0 else 1.0\n",
        "        scaled_point = point * scale\n",
        "\n",
        "        # Текущие координаты точки с учетом уже найденного потока\n",
        "        current_point = scaled_point + flow * scale\n",
        "\n",
        "        # Получаем изображения текущего уровня\n",
        "        prev_img = prev_pyramid[level]\n",
        "        curr_img = curr_pyramid[level]\n",
        "\n",
        "        # Итеративно уточняем позицию\n",
        "        for _ in range(max_iterations):\n",
        "            # Округляем координаты для извлечения патча\n",
        "            x, y = int(round(current_point[0])), int(round(current_point[1]))\n",
        "\n",
        "            # Проверяем, что точка находится внутри изображения с учетом окна\n",
        "            half_window = window_size // 2\n",
        "            if (y - half_window < 0 or y + half_window >= prev_img.shape[0] or\n",
        "                x - half_window < 0 or x + half_window >= prev_img.shape[1]):\n",
        "                return None\n",
        "\n",
        "            # Извлекаем патчи из предыдущего и текущего кадров\n",
        "            prev_patch = prev_img[y-half_window:y+half_window+1, x-half_window:x+half_window+1]\n",
        "            curr_patch = curr_img[y-half_window:y+half_window+1, x-half_window:x+half_window+1]\n",
        "\n",
        "            # Проверяем, что патчи имеют правильный размер\n",
        "            if prev_patch.shape[0] != window_size or prev_patch.shape[1] != window_size:\n",
        "                return None\n",
        "\n",
        "            # Вычисляем оптический поток для патча\n",
        "            delta_flow = compute_lk_optical_flow_for_patch(prev_patch, curr_patch, window_size)\n",
        "\n",
        "            # Если не удалось вычислить поток, прекращаем отслеживание\n",
        "            if delta_flow[0] is None:\n",
        "                return None\n",
        "\n",
        "            # Обновляем позицию\n",
        "            current_point += np.array(delta_flow)\n",
        "\n",
        "            # Проверяем условие сходимости\n",
        "            if abs(delta_flow[0]) < epsilon and abs(delta_flow[1]) < epsilon:\n",
        "                break\n",
        "\n",
        "        # Обновляем общий поток для следующего уровня\n",
        "        flow = (current_point - scaled_point)\n",
        "\n",
        "    # Возвращаем итоговую точку\n",
        "    return (point[0] + flow[0], point[1] + flow[1])"
      ],
      "metadata": {
        "id": "CaAeUJoq-sN-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lucas_kanade_optical_flow(prev_frame, curr_frame, points,\n",
        "                             window_size=15, num_pyramid_levels=3,\n",
        "                             max_iterations=100, epsilon=0.1):\n",
        "    # Преобразуем входные кадры в полутоновые, если они цветные\n",
        "    if len(prev_frame.shape) == 3:\n",
        "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        prev_gray = prev_frame\n",
        "\n",
        "    if len(curr_frame.shape) == 3:\n",
        "        curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        curr_gray = curr_frame\n",
        "\n",
        "    # Нормализуем изображения к диапазону [0, 1]\n",
        "    prev_gray = prev_gray.astype(np.float32) / 255.0\n",
        "    curr_gray = curr_gray.astype(np.float32) / 255.0\n",
        "\n",
        "    # Создаем пирамиды изображений\n",
        "    prev_pyramid = build_image_pyramid(prev_gray, num_pyramid_levels)\n",
        "    curr_pyramid = build_image_pyramid(curr_gray, num_pyramid_levels)\n",
        "\n",
        "    # Подготавливаем массивы для результатов\n",
        "    new_points = np.zeros_like(points, dtype=np.float32)\n",
        "    status = np.zeros(len(points), dtype=np.int32)\n",
        "\n",
        "    # Обрабатываем каждую точку\n",
        "    for i, point in enumerate(points):\n",
        "        # Отслеживаем точку с помощью пирамидального LK\n",
        "        new_point = track_point_with_pyramid_lk(\n",
        "            prev_pyramid, curr_pyramid, point,\n",
        "            window_size, max_iterations, epsilon\n",
        "        )\n",
        "\n",
        "        # Сохраняем результат и статус\n",
        "        if new_point is not None:\n",
        "            new_points[i] = new_point\n",
        "            status[i] = 1  # Успешное отслеживание\n",
        "        else:\n",
        "            new_points[i] = point  # Сохраняем исходную точку\n",
        "            status[i] = 0  # Неуспешное отслеживание\n",
        "\n",
        "    return new_points, status"
      ],
      "metadata": {
        "id": "RtUa__4_9S6l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_optical_flow(video_path='data/slow_traffic_small.mp4', output_path='output_my_LK.mp4'):\n",
        "    \"\"\"\n",
        "    Демонстрация работы алгоритма на видео.\n",
        "\n",
        "    Args:\n",
        "        video_path: Путь к входному видео\n",
        "        output_path: Путь для сохранения результата\n",
        "    \"\"\"\n",
        "    # Открываем видео\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Получаем параметры видео\n",
        "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Настраиваем запись выходного видео\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Параметры для обнаружения углов Shi-Tomasi\n",
        "    feature_params = dict(\n",
        "        maxCorners=100,\n",
        "        qualityLevel=0.3,\n",
        "        minDistance=7,\n",
        "        blockSize=7\n",
        "    )\n",
        "\n",
        "    # Берем первый кадр и находим в нем углы\n",
        "    ret, old_frame = cap.read()\n",
        "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "    p0 = p0.reshape(-1, 2)  # Преобразуем в формат [[x1, y1], [x2, y2], ...]\n",
        "\n",
        "    # Сохраняем изначальные точки для отслеживания через все видео\n",
        "    initial_points = p0.copy()\n",
        "\n",
        "    # Создаем маску для рисования\n",
        "    mask = np.zeros_like(old_frame)\n",
        "\n",
        "    # Создаем случайные цвета для визуализации\n",
        "    color = np.random.randint(0, 255, (len(p0), 3))\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    for i in tqdm(range(length - 1)):  # -1 потому что первый кадр мы уже прочитали\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print('No frames grabbed!')\n",
        "            break\n",
        "\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Вычисляем оптический поток с помощью нашей реализации\n",
        "        p1, st = lucas_kanade_optical_flow(\n",
        "            old_gray,\n",
        "            frame_gray,\n",
        "            p0,\n",
        "            window_size=15,\n",
        "            num_pyramid_levels=3\n",
        "        )\n",
        "\n",
        "        # Выбираем хорошие точки\n",
        "        good_new = p1[st == 1]\n",
        "        good_old = p0[st == 1]\n",
        "\n",
        "        # Рисуем треки\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new\n",
        "            c, d = old\n",
        "            mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i % len(color)].tolist(), 2)\n",
        "            frame = cv2.circle(frame, (int(a), int(b)), 5, color[i % len(color)].tolist(), -1)\n",
        "\n",
        "        # Объединяем кадр и маску\n",
        "        img = cv2.add(frame, mask)\n",
        "\n",
        "        # Записываем результат\n",
        "        out.write(img)\n",
        "\n",
        "        # Обновляем предыдущий кадр\n",
        "        old_gray = frame_gray.copy()\n",
        "\n",
        "        # Обновляем точки, но только те, которые успешно отслежены\n",
        "        p0[st == 1] = good_new\n",
        "\n",
        "    # Освобождаем ресурсы\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Результат сохранен в {output_path}\")\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "cqSeVLOl_y3I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_path = demo_optical_flow(video_path='data/slow_traffic_small.mp4', output_path='output_my_LK.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqvnCf7yFEVw",
        "outputId": "7634bff2-ac2f-43d1-d360-a2efbc368c87"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 913/913 [00:20<00:00, 44.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат сохранен в output_my_LK.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgqX4BTW3rMc"
      },
      "source": [
        "### Релизация OpenCV - cv2.calcOpticalFlowPyrLK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bAEciGA83rMc"
      },
      "outputs": [],
      "source": [
        "def demo_optical_flow_opencv(video_path='data/slow_traffic_small.mp4', output_path='output_my_LK.mp4'):\n",
        "    \"\"\"\n",
        "    Демонстрация работы алгоритма на видео с использованием cv2.calcOpticalFlowPyrLK.\n",
        "\n",
        "    Args:\n",
        "        video_path: Путь к входному видео\n",
        "        output_path: Путь для сохранения результата\n",
        "    \"\"\"\n",
        "    # Открываем видео\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Получаем параметры видео\n",
        "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Настраиваем запись выходного видео\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Параметры для обнаружения углов Shi-Tomasi\n",
        "    feature_params = dict(\n",
        "        maxCorners=100,\n",
        "        qualityLevel=0.3,\n",
        "        minDistance=7,\n",
        "        blockSize=7\n",
        "    )\n",
        "\n",
        "    # Параметры для Lucas-Kanade оптического потока\n",
        "    lk_params = dict(\n",
        "        winSize=(15, 15),\n",
        "        maxLevel=3,\n",
        "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
        "    )\n",
        "\n",
        "    # Берем первый кадр и находим в нем углы\n",
        "    ret, old_frame = cap.read()\n",
        "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "\n",
        "    # Создаем маску для рисования\n",
        "    mask = np.zeros_like(old_frame)\n",
        "\n",
        "    # Создаем случайные цвета для визуализации\n",
        "    color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    for i in tqdm(range(length - 1)):  # -1 потому что первый кадр мы уже прочитали\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print('No frames grabbed!')\n",
        "            break\n",
        "\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Вычисляем оптический поток с помощью встроенной функции cv2.calcOpticalFlowPyrLK\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "        # Выбираем хорошие точки\n",
        "        if p1 is not None:\n",
        "            good_new = p1[st == 1]\n",
        "            good_old = p0[st == 1]\n",
        "\n",
        "        # Рисуем треки\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new.ravel()\n",
        "            c, d = old.ravel()\n",
        "            mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i % len(color)].tolist(), 2)\n",
        "            frame = cv2.circle(frame, (int(a), int(b)), 5, color[i % len(color)].tolist(), -1)\n",
        "\n",
        "        # Объединяем кадр и маску\n",
        "        img = cv2.add(frame, mask)\n",
        "\n",
        "        # Записываем результат\n",
        "        out.write(img)\n",
        "\n",
        "        # Обновляем предыдущий кадр\n",
        "        old_gray = frame_gray.copy()\n",
        "\n",
        "        # Обновляем точки, но только те, которые успешно отслежены\n",
        "        p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    # Освобождаем ресурсы\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Результат сохранен в {output_path}\")\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9jLzPVL3rMc",
        "outputId": "8ccac1b2-c040-4b97-edef-f7335bc0ff79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 913/913 [00:05<00:00, 163.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат сохранен в output_opencv_LK.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "result_path = demo_optical_flow_opencv(video_path='data/slow_traffic_small.mp4', output_path='output_opencv_LK.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oweAxRW13rMd"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "В базовой реализации у кода есть одна важная проблема - ключевые точки инициализируются единожды. В реальных задачах необходимо отслеживать точки, которые исчезают из кадра и появляются в других местах. Реализуйте механизм, который будет отслеживать точки, которые пропадают из кадра и добавлять новые точки в те места, где они появляются. Для этого вам нужно будет реализовать механизм поиска новых точек на изображении."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hsztA0Wp3rMd"
      },
      "outputs": [],
      "source": [
        "def demo_optical_flow_enhanced(video_path='data/slow_traffic_small.mp4', output_path='output_my_LK_enhanced.mp4'):\n",
        "    \"\"\"\n",
        "    Демонстрация работы алгоритма на видео.\n",
        "\n",
        "    Args:\n",
        "        video_path: Путь к входному видео\n",
        "        output_path: Путь для сохранения результата\n",
        "    \"\"\"\n",
        "    # Открываем видео\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Получаем параметры видео\n",
        "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Настраиваем запись выходного видео\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Параметры для обнаружения углов Shi-Tomasi\n",
        "    feature_params = dict(\n",
        "        maxCorners=100,\n",
        "        qualityLevel=0.3,\n",
        "        minDistance=7,\n",
        "        blockSize=7\n",
        "    )\n",
        "\n",
        "    # Берем первый кадр и находим в нем углы\n",
        "    ret, old_frame = cap.read()\n",
        "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "    p0 = p0.reshape(-1, 2)  # Преобразуем в формат [[x1, y1], [x2, y2], ...]\n",
        "\n",
        "    # Создаем маску для рисования треков\n",
        "    mask = np.zeros_like(old_frame)\n",
        "\n",
        "    # Создаем случайные цвета для визуализации\n",
        "    color = np.random.randint(0, 255, (500, 3))  # Увеличиваем размер массива цветов\n",
        "\n",
        "    # Минимальное число точек, при котором необходимо искать новые\n",
        "    min_points = 20\n",
        "\n",
        "    # Для хранения всех идентификаторов точек\n",
        "    point_ids = np.arange(len(p0))\n",
        "    next_id = len(p0)\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    for i in tqdm(range(length - 1)):  # -1 потому что первый кадр мы уже прочитали\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print('No frames grabbed!')\n",
        "            break\n",
        "\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Вычисляем оптический поток с помощью нашей реализации\n",
        "        p1, st = lucas_kanade_optical_flow(\n",
        "            old_gray,\n",
        "            frame_gray,\n",
        "            p0,\n",
        "            window_size=15,\n",
        "            num_pyramid_levels=3\n",
        "        )\n",
        "\n",
        "        # Выбираем хорошие точки\n",
        "        good_new = p1[st == 1]\n",
        "        good_old = p0[st == 1]\n",
        "        good_ids = point_ids[st == 1]\n",
        "\n",
        "        # Обновляем массивы точек и их идентификаторов\n",
        "        p0 = good_new\n",
        "        point_ids = good_ids\n",
        "\n",
        "        # Проверяем, нужно ли добавить новые точки\n",
        "        if len(p0) < min_points:\n",
        "            # Создаем маску, исключающую области вокруг существующих точек\n",
        "            mask_points = np.zeros_like(old_gray)\n",
        "\n",
        "            for x, y in p0:\n",
        "                cv2.circle(mask_points, (int(x), int(y)), 10, 255, -1)  # Радиус 10 пикселей\n",
        "\n",
        "            mask_points = cv2.bitwise_not(mask_points)\n",
        "\n",
        "            # Ищем новые точки, исключая области с существующими точками\n",
        "            new_features = cv2.goodFeaturesToTrack(\n",
        "                frame_gray,\n",
        "                mask=mask_points,\n",
        "                maxCorners=100 - len(p0),  # Дополняем до максимального количества\n",
        "                qualityLevel=0.2,          # Немного снижаем требования к качеству\n",
        "                minDistance=7,\n",
        "                blockSize=7\n",
        "            )\n",
        "\n",
        "            if new_features is not None:\n",
        "                new_features = new_features.reshape(-1, 2)\n",
        "\n",
        "                # Создаем новые идентификаторы для новых точек\n",
        "                new_ids = np.arange(next_id, next_id + len(new_features))\n",
        "                next_id += len(new_features)\n",
        "\n",
        "                # Добавляем новые точки и их идентификаторы\n",
        "                p0 = np.vstack([p0, new_features]) if len(p0) > 0 else new_features\n",
        "                point_ids = np.concatenate([point_ids, new_ids]) if len(point_ids) > 0 else new_ids\n",
        "\n",
        "                # Обновляем массив цветов, если необходимо\n",
        "                if next_id > len(color):\n",
        "                    new_colors = np.random.randint(0, 255, (500, 3))\n",
        "                    color = np.vstack([color, new_colors])\n",
        "\n",
        "        # Рисуем треки\n",
        "        for i, (new, old, point_id) in enumerate(zip(good_new, good_old, good_ids)):\n",
        "            a, b = new\n",
        "            c, d = old\n",
        "            mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[point_id % len(color)].tolist(), 2)\n",
        "            frame = cv2.circle(frame, (int(a), int(b)), 5, color[point_id % len(color)].tolist(), -1)\n",
        "\n",
        "        # Объединяем кадр и маску\n",
        "        img = cv2.add(frame, mask)\n",
        "\n",
        "        # Записываем результат\n",
        "        out.write(img)\n",
        "\n",
        "        # Обновляем предыдущий кадр\n",
        "        old_gray = frame_gray.copy()\n",
        "\n",
        "    # Освобождаем ресурсы\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Результат сохранен в {output_path}\")\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_optical_flow_enhanced()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "AFeRrDnPWEZq",
        "outputId": "33c0fee1-8274-46db-9e70-12cd36dcf08e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 913/913 [00:51<00:00, 17.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат сохранен в output_my_LK_enhanced.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output_my_LK_enhanced.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goj4JFKq3rMd"
      },
      "source": [
        "### Вопрос 4\n",
        "\n",
        "В чем основное отличие разреженного (sparse) оптического потока Lucas-Kanade от плотного (dense) оптического потока (например, метода Farneback)?\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "Разреженный поток (sparse) вычисляется только в отдельных ключевых точках, плотный поток (dense) вычисляется для каждого пикселя изображения.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EiMO68S3rMd"
      },
      "source": [
        "## Farneback (dense)\n",
        "\n",
        "Метод Farneback носит несколько более глобальный характер, чем метод Лукаса-Канаде. Он опирается на предположение о том, что на всем изображении оптический поток будет достаточно гладким."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu6X-Tgl3rMd"
      },
      "source": [
        "# Вопрос 5\n",
        "\n",
        "Перечислите основные шаги алгоритма Farneback для расчета оптического потока.\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "# Алгоритм Фарнебэка для расчета оптического потока\n",
        "\n",
        "Алгоритм Farneback оценивает **плотный оптический поток** между двумя кадрами, моделируя локальные области с помощью квадратичных полиномов и итеративно уточняя смещения.\n",
        "\n",
        "## 1. Полиномиальная аппроксимация\n",
        "\n",
        "Каждое окно изображения $I(x)$, где $x = (x, y)$, аппроксимируется квадратичной функцией:\n",
        "\n",
        "$$\n",
        "I(x) \\approx x^T A x + b^T x + c\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $A \\in \\mathbb{R}^{2 \\times 2}$ — матрица кривизны;\n",
        "- $b \\in \\mathbb{R}^2$ — вектор градиента;\n",
        "- $c \\in \\mathbb{R}$ — скалярное смещение.\n",
        "\n",
        "## 2. Предположение о смещении\n",
        "\n",
        "Предполагается, что смещение $d = (u, v)$ между кадрами влияет на интенсивность во втором кадре:\n",
        "\n",
        "$$\n",
        "J(x) = I(x - d) \\approx (x - d)^T A' (x - d) + b'^T (x - d) + c'\n",
        "$$\n",
        "\n",
        "## 3. Линеаризация уравнения\n",
        "\n",
        "Разность аппроксимаций выражается через $d$:\n",
        "\n",
        "$$\n",
        "\\Delta I(x) \\approx (A + A') d + (b - b')\n",
        "$$\n",
        "\n",
        "## 4. Метод наименьших квадратов\n",
        "\n",
        "Для минимизации ошибки решается система:\n",
        "\n",
        "$$\n",
        "d = (A^T W A)^{-1} A^T W b\n",
        "$$\n",
        "\n",
        "где $W$ — весовая матрица (например, гауссово окно), учитывающая вклад пикселей.\n",
        "\n",
        "## 5. Весовая агрегация\n",
        "\n",
        "Используется **Гауссов фильтр** для сглаживания оценок коэффициентов полинома. Это повышает устойчивость алгоритма к шуму и локальным выбросам.\n",
        "\n",
        "## 6. Многомасштабный подход\n",
        "\n",
        "Строится **пирамида изображений**:\n",
        "\n",
        "- Поток сначала оценивается на самом грубом уровне (низкое разрешение);\n",
        "- Затем он интерполируется и используется как инициализация на следующем уровне;\n",
        "- Уточнение продолжается до самого высокого разрешения.\n",
        "\n",
        "## 7. Итеративное уточнение\n",
        "\n",
        "На каждом уровне пирамиды проводится несколько итераций уточнения потока $d$ для повышения точности.\n",
        "\n",
        "---\n",
        "\n",
        "## Вывод\n",
        "\n",
        "Алгоритм Фарнебэка сочетает:\n",
        "- Квадратичную полиномиальную аппроксимацию;\n",
        "- Метод наименьших квадратов с весами;\n",
        "- Гауссовое сглаживание;\n",
        "- Многомасштабный анализ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTTftwwp3rMd"
      },
      "source": [
        "### Вопрос 6\n",
        "\n",
        "Каким образом в методе Farneback обрабатываются большие смещения объектов между кадрами?\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "Для обработки больших смещений в методе Farneback используется **многомасштабный (пирамидальный) подход**:\n",
        "\n",
        "- Строится **гауссова пирамида изображений**: на каждом следующем уровне изображение уменьшается (разрешение снижается);\n",
        "- **Оценка оптического потока начинается с самого грубого уровня** (малого разрешения), где большие смещения превращаются в относительно маленькие;\n",
        "- Затем поток **интерполируется** на следующий, более детализированный уровень и **используется как инициализация**;\n",
        "- На каждом уровне проводится **итеративное уточнение** потока.\n",
        "\n",
        "Таким образом, даже при значительных перемещениях объектов, метод способен постепенно приблизиться к корректной оценке смещений, избегая локальных минимумов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vFTd6BtE3rMd"
      },
      "outputs": [],
      "source": [
        "def demo_optical_flow_farneback_opencv(video_path='data/slow_traffic_small.mp4', output_path='output_Farneback.mp4'):\n",
        "    \"\"\"\n",
        "    Демонстрация работы алгоритма плотного оптического потока Farneback на видео.\n",
        "\n",
        "    Args:\n",
        "        video_path: Путь к входному видео\n",
        "        output_path: Путь для сохранения результата\n",
        "    \"\"\"\n",
        "    # Открываем видео\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Получаем параметры видео\n",
        "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Настраиваем запись выходного видео\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Берем первый кадр и преобразуем его в оттенки серого\n",
        "    ret, frame1 = cap.read()\n",
        "    if not ret:\n",
        "        print('Не удалось прочитать видео')\n",
        "        return None\n",
        "\n",
        "    prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Создаем HSV-изображение для визуализации потока\n",
        "    hsv = np.zeros_like(frame1)\n",
        "    hsv[..., 1] = 255  # Насыщенность устанавливаем на максимум\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    for i in tqdm(range(length - 1)):  # -1 потому что первый кадр мы уже прочитали\n",
        "        ret, frame2 = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print('No frames grabbed!')\n",
        "            break\n",
        "\n",
        "        next_frame = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Вычисляем оптический поток методом Farneback\n",
        "        # Параметры:\n",
        "        # - 0.5: коэффициент масштабирования для пирамиды изображений\n",
        "        # - 3: кол-во уровней пирамиды\n",
        "        # - 15: размер окна для усреднения\n",
        "        # - 3: число итераций на каждом уровне пирамиды\n",
        "        # - 5: размер окна для полиномиальной аппроксимации\n",
        "        # - 1.2: стандартное отклонение для сглаживания\n",
        "        flow = cv2.calcOpticalFlowFarneback(\n",
        "            prvs, next_frame, None,\n",
        "            0.5, 3, 15, 3, 5, 1.2, 0\n",
        "        )\n",
        "\n",
        "        # Преобразуем векторы потока из декартовых координат в полярные\n",
        "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "\n",
        "        # Кодируем направление потока как оттенок (hue)\n",
        "        hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "\n",
        "        # Кодируем величину потока как яркость (value)\n",
        "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "        # Преобразуем HSV в BGR для отображения\n",
        "        bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        # Записываем результат\n",
        "        out.write(bgr)\n",
        "\n",
        "        # Обновляем предыдущий кадр\n",
        "        prvs = next_frame\n",
        "\n",
        "    # Освобождаем ресурсы\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Результат сохранен в {output_path}\")\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hVWlJMz03rMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f07baf-8997-48ec-ecd3-873576f59705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 913/913 [01:31<00:00, 10.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат сохранен в output_opencv_farneback.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "result_path = demo_optical_flow_farneback_opencv(video_path='data/slow_traffic_small.mp4', output_path='output_opencv_farneback.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bMh23te3rMe"
      },
      "source": [
        "### Вопрос 7\n",
        "\n",
        "Как влияет предварительная обработка изображений (фильтрация шума, выравнивание гистограмм) на качество оптического потока, получаемого методом Farneback? Предложите оптимальный пайплайн предобработки.\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "Предварительная обработка изображений повышает устойчивость и точность оптического потока, особенно при использовании метода Farneback, который чувствителен к шуму и локальным изменениям контраста.\n",
        "\n",
        "#### Влияние предобработки:\n",
        "\n",
        "- **Фильтрация шума** (например, Gaussian Blur):\n",
        "  - Устраняет высокочастотный шум, который может искажать локальные полиномиальные аппроксимации;\n",
        "  - Улучшает устойчивость оценки градиентов и матрицы $A$.\n",
        "\n",
        "- **Выравнивание гистограмм**:\n",
        "  - Нормализует контраст на изображении, особенно полезно при переменном освещении;\n",
        "  - Повышает качество сопоставления между окнами в разных кадрах.\n",
        "\n",
        "- **Градации серого (grayscale)**:\n",
        "  - Метод Farneback работает с интенсивностями, поэтому перевод в оттенки серого упрощает обработку и снижает размер входных данных.\n",
        "\n",
        "---\n",
        "\n",
        "### Оптимальный пайплайн предобработки для Farneback:\n",
        "\n",
        "1. **Приведение к градациям серого**:\n",
        "   ```python\n",
        "   gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "2. **Гауссово сглаживание**:\n",
        "   ```python\n",
        "   blurred = cv2.GaussianBlur(gray, (5, 5), sigmaX=1.5)\n",
        "\n",
        "3. **Выравнивание гистограммы:**:\n",
        "   ```python\n",
        "   equalized = cv2.equalizeHist(blurred)\\\n",
        "\n",
        "4. **Передача в cv2.calcOpticalFlowFarneback()**:\n",
        "   ```python\n",
        "   flow = cv2.calcOpticalFlowFarneback(prev=equalized1, next=equalized2, ...)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cv_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}